{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vABBObIO_ET6"
      },
      "id": "vABBObIO_ET6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c4825d3",
      "metadata": {
        "id": "8c4825d3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import utils\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import SVG, Image\n",
        "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
        "from keras.utils.vis_utils import plot_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aaf3792",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aaf3792",
        "outputId": "cd1c110e-1e9a-4d40-d25e-8ef15c768361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7215 happy images\n",
            "4965 neutral images\n",
            "3171 surprise images\n",
            "4830 sad images\n",
            "4097 fear images\n",
            "4138 angry images\n",
            "436 disgust images\n"
          ]
        }
      ],
      "source": [
        "for ex in os.listdir('drive/MyDrive/Colab Notebooks/Take 2/train'):\n",
        "    print(str(len(os.listdir(\"drive/MyDrive/Colab Notebooks/Take 2/train/\" + ex))) + \" \" + ex + \" images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e1a6b6",
      "metadata": {
        "id": "06e1a6b6",
        "outputId": "aca35e86-d61c-4067-c856-c5fe5e6b947b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28852 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "img = 48\n",
        "batch = 64\n",
        "data_train = ImageDataGenerator(horizontal_flip=True)\n",
        "train_gen = data_train.flow_from_directory(\"drive/MyDrive/Colab Notebooks/Take 2/train\",\n",
        "                                                    target_size=(img,img),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "data_test = ImageDataGenerator(horizontal_flip=True)\n",
        "test_gen = data_test.flow_from_directory(\"drive/MyDrive/Colab Notebooks/Take 2/test\",\n",
        "                                                    target_size=(img,img),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d764bab2",
      "metadata": {
        "id": "d764bab2",
        "outputId": "2b8db71e-e590-409c-e07f-b0ff3668b827",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 48, 48, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 24, 24, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 24, 24, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 24, 24, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 12, 12, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 12, 12, 512)       590336    \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 12, 12, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 6, 6, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 6, 6, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 3, 3, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               1179904   \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,478,727\n",
            "Trainable params: 4,474,759\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "face_model = Sequential()\n",
        "\n",
        "# 1 - Convolution\n",
        "face_model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
        "face_model.add(BatchNormalization())\n",
        "face_model.add(Activation('relu'))\n",
        "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "face_model.add(Dropout(0.25))\n",
        "\n",
        "# 2 - Convolution\n",
        "face_model.add(Conv2D(128,(5,5), padding='same'))\n",
        "face_model.add(BatchNormalization())\n",
        "face_model.add(Activation('relu'))\n",
        "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "face_model.add(Dropout(0.25))\n",
        "\n",
        "# 3 - Convolution\n",
        "face_model.add(Conv2D(512,(3,3), padding='same'))\n",
        "face_model.add(BatchNormalization())\n",
        "face_model.add(Activation('relu'))\n",
        "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "face_model.add(Dropout(0.25))\n",
        "\n",
        "# 4 - Convolution\n",
        "face_model.add(Conv2D(512,(3,3), padding='same'))\n",
        "face_model.add(BatchNormalization())\n",
        "face_model.add(Activation('relu'))\n",
        "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "face_model.add(Dropout(0.25))\n",
        "\n",
        "# Flattening\n",
        "face_model.add(Flatten())\n",
        "\n",
        "# 1 - Fully connected layer \n",
        "face_model.add(Dense(256))\n",
        "face_model.add(BatchNormalization())\n",
        "face_model.add(Activation('relu'))\n",
        "face_model.add(Dropout(0.25))\n",
        "\n",
        "# 2 - Fully connected layer\n",
        "face_model.add(Dense(512))\n",
        "face_model.add(BatchNormalization())\n",
        "face_model.add(Activation('relu'))\n",
        "face_model.add(Dropout(0.25))\n",
        "\n",
        "face_model.add(Dense(7, activation='softmax'))\n",
        "opt = Adam(learning_rate=0.0005)\n",
        "face_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "face_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6689934f",
      "metadata": {
        "id": "6689934f"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "epochs = 15\n",
        "steps = train_gen.n//train_gen.batch_size\n",
        "test_steps = test_gen.n//test_gen.batch_size\n",
        "dec_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=2, min_lr=0.00001, mode='auto')\n",
        "cp = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n",
        "                             save_weights_only=True, mode='max', verbose=1)\n",
        "callbacks = [PlotLossesCallback(), cp, dec_lr]\n",
        "history = face_model.fit(\n",
        "    x=train_gen,\n",
        "    steps_per_epoch=steps,\n",
        "    epochs=epochs,\n",
        "    validation_data = test_gen,\n",
        "    validation_steps = test_steps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e41a9db",
      "metadata": {
        "id": "5e41a9db"
      },
      "outputs": [],
      "source": [
        "model_json = face_model.to_json()\n",
        "face_model.save_weights('model_weights.h5')\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57705183",
      "metadata": {
        "id": "57705183"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "class FacialExpressionModel(object):\n",
        "    EMOTIONS_LIST = [\"Angry\", \"Disgust\",\n",
        "                    \"Fear\", \"Happy\",\n",
        "                    \"Neutral\", \"Sad\",\n",
        "                    \"Surprise\"]\n",
        "    def __init__(self, model_json_file, model_weights_file):\n",
        "        # load model from JSON file\n",
        "        with open(model_json_file, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            self.loaded_model = model_from_json(loaded_model_json)\n",
        "        # load weights into the new model\n",
        "        self.loaded_model.load_weights(model_weights_file)\n",
        "        self.loaded_model.make_predict_function()\n",
        "    def predict_emotion(self, img):\n",
        "        self.preds = self.loaded_model.predict(img)\n",
        "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cae4b92",
      "metadata": {
        "id": "3cae4b92"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "facec = cv2.CascadeClassifier(\"drive/MyDrive/Colab Notebooks/Take 2/haarcascade_frontalface_default.xml/\")\n",
        "model = FacialExpressionModel(\"model.json\", \"model_weights.h5\")\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "class VideoCamera(object):\n",
        "    def __init__(self):\n",
        "        self.video = cv2.VideoCapture(-1)\n",
        "    def __del__(self):\n",
        "        self.video.release()\n",
        "    # returns camera frames along with bounding boxes and predictions\n",
        "    def get_frame(self):\n",
        "        _, fr = self.video.read()\n",
        "        gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
        "        faces = facec.detectMultiScale(gray_fr, 1.3, 5)\n",
        "        for (x, y, w, h) in faces:\n",
        "            fc = gray_fr[y:y+h, x:x+w]\n",
        "            roi = cv2.resize(fc, (48, 48))\n",
        "            pred = model.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n",
        "            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n",
        "            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        return fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5e4c5c",
      "metadata": {
        "id": "9f5e4c5c"
      },
      "outputs": [],
      "source": [
        "def gen(camera):\n",
        "    while True:\n",
        "        frame = camera.get_frame()\n",
        "        cv2.imshow('Facial Expression Recognization',frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd3026ef",
      "metadata": {
        "id": "dd3026ef"
      },
      "outputs": [],
      "source": [
        "gen(VideoCamera())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLLlksrKDVR6"
      },
      "id": "BLLlksrKDVR6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}